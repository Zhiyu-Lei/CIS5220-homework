{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee344e43-7e8d-40ee-935f-2b304ae1998e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size: int,\n",
    "        hidden_size: int,\n",
    "        num_classes: int,\n",
    "        hidden_count: int = 1,\n",
    "        activation: Callable = torch.nn.ReLU,\n",
    "        initializer: Callable = torch.nn.init.ones_,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the MLP.\n",
    "\n",
    "        Arguments:\n",
    "            input_size: The dimension D of the input data.\n",
    "            hidden_size: The number of neurons H in the hidden layer.\n",
    "            num_classes: The number of classes C.\n",
    "            hidden_count: The number of hidden layers.\n",
    "            activation: The activation function to use in the hidden layer.\n",
    "            initializer: The initializer to use for the weights.\n",
    "        \"\"\"\n",
    "        super(MLP, self).__init__()\n",
    "        self.activation = activation()\n",
    "        self.hidden_layers = [torch.nn.Linear(input_size, hidden_size)]\n",
    "        initializer(self.hidden_layers[0].weight)\n",
    "        for _ in range(1, hidden_count):\n",
    "            self.hidden_layers.append(torch.nn.Linear(hidden_size, hidden_size))\n",
    "            initializer(self.hidden_layers[-1].weight)\n",
    "        self.output_layer = torch.nn.Linear(hidden_size, num_classes)\n",
    "        initializer(self.output_layer.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the network.\n",
    "\n",
    "        Arguments:\n",
    "            x: The input data.\n",
    "\n",
    "        Returns:\n",
    "            The output of the network.\n",
    "        \"\"\"\n",
    "        for hidden_layer in self.hidden_layers:\n",
    "            x = self.activation(hidden_layer(x))\n",
    "        return self.output_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74a91bba-0d5f-43fc-b6e7-30aee768ffd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MNIST:\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor, Compose\n",
    "\n",
    "# PyTorch:\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "# Other:\n",
    "from typing import Tuple\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "_transform_list = [\n",
    "    ToTensor(),\n",
    "    lambda x: x.view(-1),\n",
    "]\n",
    "\n",
    "\n",
    "def get_mnist_data() -> Tuple[DataLoader, DataLoader]:\n",
    "    \"\"\"\n",
    "    Get the MNIST data from torchvision.\n",
    "\n",
    "    Arguments:\n",
    "        None\n",
    "\n",
    "    Returns:\n",
    "        train_loader (DataLoader): The training data loader.\n",
    "        test_loader (DataLoader): The test data loader.\n",
    "\n",
    "    \"\"\"\n",
    "    # Get the training data:\n",
    "    train_data = MNIST(\n",
    "        root=\"data\", train=True, download=True, transform=Compose(_transform_list)\n",
    "    )\n",
    "    # Create a data loader for the training data:\n",
    "    train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "    # Get the test data:\n",
    "    test_data = MNIST(\n",
    "        root=\"data\", train=False, download=True, transform=Compose(_transform_list)\n",
    "    )\n",
    "    # Create a data loader for the test data:\n",
    "    test_loader = DataLoader(test_data, batch_size=64, shuffle=True)\n",
    "    # Return the data loaders:\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "def train(\n",
    "    model: torch.nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    test_loader: DataLoader,\n",
    "    num_epochs: int,\n",
    "    learning_rate: float,\n",
    "    device: torch.device,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Train a model on the MNIST data.\n",
    "\n",
    "    Arguments:\n",
    "        model (torch.nn.Module): The model to train.\n",
    "        train_loader (DataLoader): The training data loader.\n",
    "        test_loader (DataLoader): The test data loader.\n",
    "        num_epochs (int): The number of epochs to train for.\n",
    "        learning_rate (float): The learning rate to use.\n",
    "        device (torch.device): The device to use for training.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    \"\"\"\n",
    "    # Create an optimizer:\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "    # Create a loss function:\n",
    "    criterion = CrossEntropyLoss()\n",
    "    # Move the model to the device:\n",
    "    model.to(device)\n",
    "    # Create a progress bar:\n",
    "    progress_bar = tqdm(range(num_epochs))\n",
    "    # Train the model:\n",
    "    for epoch in progress_bar:\n",
    "        # Set the model to training mode:\n",
    "        model.train()\n",
    "        # Iterate over the training data:\n",
    "        for batch in train_loader:\n",
    "            # Get the data and labels:\n",
    "            data, labels = batch\n",
    "            # Move the data and labels to the device:\n",
    "            data = data.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # Zero the gradients:\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass:\n",
    "            outputs = model(data)\n",
    "            # Calculate the loss:\n",
    "            loss = criterion(outputs, labels)\n",
    "            # Backward pass:\n",
    "            loss.backward()\n",
    "            # Update the parameters:\n",
    "            optimizer.step()\n",
    "        # Set the model to evaluation mode:\n",
    "        model.eval()\n",
    "\n",
    "        # Calculate the accuracy on the test data:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                # Get the data and labels:\n",
    "                data, labels = batch\n",
    "                # Move the data and labels to the device:\n",
    "                data = data.to(device)\n",
    "                labels = labels.to(device)\n",
    "                # Forward pass:\n",
    "                outputs = model(data)\n",
    "                # Get the predictions:\n",
    "                _, predictions = torch.max(outputs.data, 1)\n",
    "                # Update the total and correct counts:\n",
    "                total += labels.size(0)\n",
    "                correct += (predictions == labels).sum().item()\n",
    "        # Calculate the accuracy:\n",
    "        accuracy = correct / total\n",
    "        # Update the progress bar:\n",
    "        progress_bar.set_description(f\"Epoch: {epoch}, Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d16b06ab-91a0-4d8e-a6c7-b49ac39dab16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader, test_loader = get_mnist_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d3afd98-e7a1-4d33-9ae9-0a02dbda83fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5cb492a237546eea7f7b66a3e512652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model1 = MLP(784, 512, 10, 2, torch.nn.LeakyReLU, torch.nn.init.xavier_normal_)\n",
    "\n",
    "train(model=model1,\n",
    "      train_loader=train_loader,\n",
    "      test_loader=test_loader,\n",
    "      num_epochs=10,\n",
    "      learning_rate=0.001,\n",
    "      device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79341565-987d-456d-bd8a-4e2b2191269e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6279d5d454aa43dc870a19b58b161d40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model2 = MLP(784, 1024, 10, 2, torch.nn.LeakyReLU, torch.nn.init.xavier_normal_)\n",
    "\n",
    "train(model=model2,\n",
    "      train_loader=train_loader,\n",
    "      test_loader=test_loader,\n",
    "      num_epochs=10,\n",
    "      learning_rate=0.001,\n",
    "      device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9abf2c94-ed63-4444-b063-4fb470c38d03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2888fe5f3b314b93ae6de182959d48b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model3 = MLP(784, 1024, 10, 3, torch.nn.LeakyReLU, torch.nn.init.xavier_normal_)\n",
    "\n",
    "train(model=model3,\n",
    "      train_loader=train_loader,\n",
    "      test_loader=test_loader,\n",
    "      num_epochs=10,\n",
    "      learning_rate=0.001,\n",
    "      device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f99d07e-2166-426a-adf0-c35d9c2ca5e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bc0957633b64eb9ab244f9cd026d0fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model4 = MLP(784, 1500, 10, 2, torch.nn.LeakyReLU, torch.nn.init.xavier_normal_)\n",
    "\n",
    "train(model=model4,\n",
    "      train_loader=train_loader,\n",
    "      test_loader=test_loader,\n",
    "      num_epochs=10,\n",
    "      learning_rate=0.001,\n",
    "      device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21c9c8bf-67f7-4a49-b783-c6957f55f820",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cad8152d1af4310913d0bc1852ffb90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model4 = MLP(784, 512, 10, 3, torch.nn.LeakyReLU, torch.nn.init.xavier_normal_)\n",
    "\n",
    "train(model=model4,\n",
    "      train_loader=train_loader,\n",
    "      test_loader=test_loader,\n",
    "      num_epochs=10,\n",
    "      learning_rate=0.001,\n",
    "      device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "     )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
